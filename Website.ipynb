{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1221f157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m     h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1349\u001b[0m               encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1286\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1332\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1331\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders(body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1281\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1041\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m \n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:979\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 979\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1458\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1456\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m-> 1458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mwrap_socket(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock,\n\u001b[0;32m   1459\u001b[0m                                       server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:517\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    512\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    513\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    514\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msslsocket_class\u001b[38;5;241m.\u001b[39m_create(\n\u001b[0;32m    518\u001b[0m         sock\u001b[38;5;241m=\u001b[39msock,\n\u001b[0;32m    519\u001b[0m         server_side\u001b[38;5;241m=\u001b[39mserver_side,\n\u001b[0;32m    520\u001b[0m         do_handshake_on_connect\u001b[38;5;241m=\u001b[39mdo_handshake_on_connect,\n\u001b[0;32m    521\u001b[0m         suppress_ragged_eofs\u001b[38;5;241m=\u001b[39msuppress_ragged_eofs,\n\u001b[0;32m    522\u001b[0m         server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[0;32m    523\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    524\u001b[0m         session\u001b[38;5;241m=\u001b[39msession\n\u001b[0;32m    525\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1075\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1074\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1075\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1346\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1345\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1346\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 73\u001b[0m\n\u001b[0;32m     26\u001b[0m team_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATL\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAtlanta Hawks\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBOS\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBoston Celtics\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCHO\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCharlotte Hornets\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTOT\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraded\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     67\u001b[0m             }\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m#Advanced Stats\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m adv \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_html(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.basketball-reference.com/leagues/NBA_2024_advanced.html\u001b[39m\u001b[38;5;124m'\u001b[39m, match\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdvanced\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     74\u001b[0m drop_RK \u001b[38;5;241m=\u001b[39m adv[adv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRk\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRk\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     75\u001b[0m adv \u001b[38;5;241m=\u001b[39m adv\u001b[38;5;241m.\u001b[39mdrop(drop_RK\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:1205\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links)\u001b[0m\n\u001b[0;32m   1201\u001b[0m validate_header_arg(header)\n\u001b[0;32m   1203\u001b[0m io \u001b[38;5;241m=\u001b[39m stringify_path(io)\n\u001b[1;32m-> 1205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parse(\n\u001b[0;32m   1206\u001b[0m     flavor\u001b[38;5;241m=\u001b[39mflavor,\n\u001b[0;32m   1207\u001b[0m     io\u001b[38;5;241m=\u001b[39mio,\n\u001b[0;32m   1208\u001b[0m     match\u001b[38;5;241m=\u001b[39mmatch,\n\u001b[0;32m   1209\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   1210\u001b[0m     index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   1211\u001b[0m     skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[0;32m   1212\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m   1213\u001b[0m     thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[0;32m   1214\u001b[0m     attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1215\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   1216\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   1217\u001b[0m     converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[0;32m   1218\u001b[0m     na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[0;32m   1219\u001b[0m     keep_default_na\u001b[38;5;241m=\u001b[39mkeep_default_na,\n\u001b[0;32m   1220\u001b[0m     displayed_only\u001b[38;5;241m=\u001b[39mdisplayed_only,\n\u001b[0;32m   1221\u001b[0m     extract_links\u001b[38;5;241m=\u001b[39mextract_links,\n\u001b[0;32m   1222\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:986\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m p \u001b[38;5;241m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only, extract_links)\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 986\u001b[0m     tables \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mparse_tables()\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io\u001b[38;5;241m.\u001b[39mseekable():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:262\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 262\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_tables(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_doc(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:821\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    819\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 821\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(r, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_content\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:802\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio):\n\u001b[1;32m--> 802\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m urlopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    803\u001b[0m             r \u001b[38;5;241m=\u001b[39m parse(f, parser\u001b[38;5;241m=\u001b[39mparser)\n\u001b[0;32m    804\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    805\u001b[0m         \u001b[38;5;66;03m# try to parse the input in the simplest way\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:265\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    537\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPSConnection, req,\n\u001b[0;32m   1392\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context, check_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_hostname)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond>"
     ]
    }
   ],
   "source": [
    "# First let's import the packages we will use in this project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib\n",
    "plt.style.use('ggplot')\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import scipy as stats\n",
    "import time\n",
    "import html5lib\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import joblib\n",
    "from sklearn.linear_model import Ridge  # M\n",
    "from flask import Flask, render_template\n",
    "\n",
    "team_dict = {'ATL': 'Atlanta Hawks',\n",
    "'BOS':'Boston Celtics',\n",
    "'CHO': 'Charlotte Hornets',\n",
    "'CHI': 'Chicago Bulls',\n",
    "'CLE': 'Cleveland Cavaliers',\n",
    "'DAL': 'Dallas Mavericks',\n",
    "'DEN': 'Denver Nuggets',\n",
    "'DET': 'Detroit Pistons',\n",
    "'GSW': 'Golden State Warriors',\n",
    "'HOU': 'Houston Rockets',\n",
    "'IND': 'Indiana Pacers',\n",
    "'LAC': 'Los Angeles Clippers',\n",
    "'LAL': 'Los Angeles Lakers',\n",
    "'MEM': 'Memphis Grizzlies',\n",
    "'MIA': 'Miami Heat',\n",
    "'MIL': 'Milwaukee Bucks',\n",
    "'MIN': 'Minnesota Timberwolves',\n",
    "'NOP': 'New Orleans Pelicans',\n",
    "'NYK': 'New York Knicks',\n",
    "'BRK': 'Brooklyn Nets',\n",
    "'OKC': 'Oklahoma City Thunder',\n",
    "'ORL': 'Orlando Magic',\n",
    "'PHI': 'Philadelphia 76ers',\n",
    "'PHO': 'Phoenix Suns',\n",
    "'POR': 'Portland Trail Blazers',\n",
    "'SAC': 'Sacramento Kings',\n",
    "'SAS': 'San Antonio Spurs',          \n",
    "'TOR': 'Toronto Raptors',\n",
    "'UTA': 'Utah Jazz',\n",
    "'WAS': 'Washington Wizards',\n",
    "'SEA': 'Seattle SuperSonics',\n",
    "'NOK': 'New Orleans/Oklahoma City Hornets',\n",
    "'NOH': 'New Orleans Hornets',\n",
    "'CHA': 'Charlotte Bobcats',            \n",
    "'SDC': 'San Diego Clippers',\n",
    "'NJN': 'New Jersey Nets',         \n",
    "'KCK': 'Kansas City Kings',\n",
    "'WSB': 'Washington Bullets',\n",
    "'VAN': 'Vancouver Grizzlies ',\n",
    "'CHH': 'Charlotte Hornets',\n",
    "'TOT': 'Traded'\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "#Advanced Stats\n",
    "\n",
    "adv = pd.read_html('https://www.basketball-reference.com/leagues/NBA_2024_advanced.html', match='Advanced')[0]\n",
    "drop_RK = adv[adv['Rk'] == 'Rk']\n",
    "adv = adv.drop(drop_RK.index)\n",
    "advanced_list = ['Age', 'G', 'MP', 'PER', 'TS%', '3PAr',\n",
    "           'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%',\n",
    "           'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP']\n",
    "adv[advanced_list] = adv[advanced_list].astype('float64')\n",
    "adv = adv.set_index('Rk')\n",
    "#     df= df.drop(df[df['Tm'] == 'TOT'].index, axis=0)\n",
    "adv['Team'] = adv['Tm'].map(team_dict)\n",
    "adv['Player'] = adv['Player'].map(lambda title:title.rstrip('*'))\n",
    "adv= adv.drop(adv[['Unnamed: 19', 'Unnamed: 24']], axis=1)\n",
    "adv['Season'] = 'https://www.basketball-reference.com/leagues/NBA_2024_advanced.html'.split('_')[1][0:4]\n",
    "adv['ID'] = adv['Season'] + ' ' + adv['Player'] + ' ' + adv['Team']\n",
    "adv['Team ID'] = adv['Season'] + ' ' + adv['Team']\n",
    "adv.to_csv(f'C:\\\\Users\\\\Owner\\\\Documents\\\\Python Scripts\\\\NBA MVP Model files\\\\Advanced stats\\\\2024 Advanced Stats.csv')\n",
    "\n",
    "\n",
    "#normalizing it\n",
    "norm_adv = adv.copy()\n",
    "norm_adv[['G', 'MP', 'PER', 'TS%', '3PAr',\n",
    "       'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%',\n",
    "       'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP']] = (norm_adv[['G', 'MP', 'PER', 'TS%', '3PAr',\n",
    "       'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%',\n",
    "       'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP']]- norm_adv[['G', 'MP', 'PER', 'TS%', '3PAr',\n",
    "       'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%',\n",
    "       'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP']].mean()) / norm_adv[['G', 'MP', 'PER', 'TS%', '3PAr',\n",
    "       'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%',\n",
    "       'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP']].std()\n",
    "norm_adv.to_csv(f'C:\\\\Users\\\\Owner\\\\Documents\\\\Python Scripts\\\\NBA MVP Model files\\\\Advanced stats\\\\2024 Advanced Stats Normalized.csv')\n",
    "\n",
    "#Per Game\n",
    "\n",
    "per = pd.read_html('https://www.basketball-reference.com/leagues/NBA_2024_per_game.html', match='Player Per Game')[0]\n",
    "per = per.fillna(0)\n",
    "drop_RK2 = per[per['Rk'] == 'Rk']\n",
    "per = per.drop(drop_RK2.index)\n",
    "per_cols = ['Age', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%',\n",
    "       '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%',\n",
    "       'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']\n",
    "\n",
    "per[per_cols] = per[per_cols].astype('float64')\n",
    "per = per.set_index('Rk')\n",
    "#     df= df.drop(df[df['Tm'] == 'TOT'].index, axis=0)\n",
    "per['Player'] = per['Player'].map(lambda title:title.rstrip('*'))\n",
    "per['Season'] = 'https://www.basketball-reference.com/leagues/NBA_2024_per_game.html'.split('_')[1][0:4]\n",
    "per['GameScore'] = per['PTS'] + 0.4 * per['FG'] - 0.7 * per[\"FGA\"] - 0.4*(per['FTA'] - per[\"FT\"]) + 0.7 * per[\"ORB\"] + 0.3 * per[\"DRB\"] + per[\"STL\"] + 0.7 * per[\"AST\"] + 0.7 * per[\"BLK\"] - 0.4 * per[\"PF\"] - per[\"TOV\"]\n",
    "per['Team'] = per['Tm'].map(team_dict)\n",
    "per['ID'] = per['Season'] + ' ' + per['Player'] + ' ' + per['Team']\n",
    "per['Team ID'] = per['Season'] + ' ' + per['Team']\n",
    "per.to_csv(f'C:\\\\Users\\\\Owner\\\\Documents\\\\Python Scripts\\\\NBA MVP Model files\\\\Player Per Game\\\\2024 Per Game Stats.csv')\n",
    "\n",
    "#normalizing it\n",
    "norm_per = per.copy()\n",
    "norm_per[['G', 'GS', 'MP', 'FG', 'FGA', 'FG%',\n",
    "       '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%',\n",
    "       'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS','GameScore']] = (norm_per[['G', 'GS', 'MP', 'FG', 'FGA', 'FG%',\n",
    "       '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%',\n",
    "       'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS','GameScore']] - norm_per[['G', 'GS', 'MP', 'FG', 'FGA', 'FG%',\n",
    "       '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%',\n",
    "       'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS','GameScore']].mean()) / norm_per[['G', 'GS', 'MP', 'FG', 'FGA', 'FG%',\n",
    "       '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%',\n",
    "       'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS','GameScore']].std()\n",
    "norm_per.to_csv(f'C:\\\\Users\\\\Owner\\\\Documents\\\\Python Scripts\\\\NBA MVP Model files\\\\Player Per Game\\\\2024 Per Game Stats Normalized.csv')\n",
    "\n",
    "#Team Advanced Stats\n",
    "\n",
    "team = pd.read_html('https://www.basketball-reference.com/leagues/NBA_2024.html', match='Advanced Stats')[0]\n",
    "team.columns = [col[1] for col in team.columns]\n",
    "team = team.drop(['Unnamed: 22_level_1', 'Unnamed: 27_level_1'], axis=1)\n",
    "team = team.drop('Unnamed: 17_level_1', axis=1)\n",
    "team = team.set_index('Rk')\n",
    "#Dropping FT/FGA columns\n",
    "team = team.drop(team.columns[23],axis=1)\n",
    "#Dropping League Average Row\n",
    "team = team.drop(team[team['Team'] == 'League Average'].index)\n",
    "team['Team'] = team['Team'].map(lambda title:title.rstrip('*'))\n",
    "team['Season'] = 'https://www.basketball-reference.com/leagues/NBA_2024.html'.split('_')[1][0:4]\n",
    "team['Team ID'] = team['Season'] + ' ' + team['Team']\n",
    "team.to_csv(f'C:\\\\Users\\\\Owner\\\\Documents\\\\Python Scripts\\\\NBA MVP Model files\\\\Team Advanced stats\\\\2024 Team Advanced Stats.csv')\n",
    "\n",
    "#normalizing it\n",
    "\n",
    "norm_team = team.copy()\n",
    "# Subset of columns to transform\n",
    "cols = ['W', 'L', 'PW', 'PL', 'MOV', 'SOS', 'SRS', 'ORtg',\n",
    "       'DRtg', 'NRtg', 'Pace', 'FTr', '3PAr', 'TS%']\n",
    "\n",
    "def standardize(column):\n",
    "    return (column - column.mean()) / column.std()\n",
    "\n",
    "# Standardize column 'A' using the apply function\n",
    "norm_team[cols] = norm_team[cols].apply(standardize)\n",
    "norm_team.to_csv(f'C:\\\\Users\\\\Owner\\\\Documents\\\\Python Scripts\\\\NBA MVP Model files\\\\Team Advanced stats\\\\2024 Team Advanced Stats Normalized.csv')\n",
    "\n",
    "norm_team.rename(columns = {\"ORtg\": \"Team ORtg\", \"DRtg\": \"Team DRtg\", \"NRtg\": \"Team NRtg\", \"Pace\": \"Team Pace\", \"FTr\": \"Team FTr\", \"3PAr\": \"Team 3PAr\",\"TS%\": \"Team TS%\" }, inplace=True)\n",
    "team.rename(columns = {\"ORtg\": \"Team ORtg\", \"DRtg\": \"Team DRtg\", \"NRtg\": \"Team NRtg\", \"Pace\": \"Team Pace\", \"FTr\": \"Team FTr\", \"3PAr\": \"Team 3PAr\",\"TS%\": \"Team TS%\" }, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Combining Dataframe\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# the path to your csv file directory\n",
    "mycsvdir = 'C:\\\\Users\\\\Owner\\\\Documents\\\\Python Scripts\\\\NBA MVP Model files\\\\Player Per Game\\\\'\n",
    "\n",
    "\n",
    "\n",
    "# get all the csv files in that directory (assuming they have the extension .csv)\n",
    "csvfiles = glob.glob(os.path.join(mycsvdir, '*Normalized.csv'))\n",
    "\n",
    "# loop through the files and read them in with pandas\n",
    "dataframes = []  # a list to hold all the individual pandas DataFrames\n",
    "for n in range(0,45):\n",
    "    df = pd.read_csv(csvfiles[n])\n",
    "    dataframes.append(df)\n",
    "\n",
    "    \n",
    "# concatenate them all together\n",
    "all_per_norm = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# print out to a new csv file\n",
    "all_per_norm.to_csv('all_per_norm.csv')\n",
    "\n",
    "all_per_norm = all_per_norm.drop('Unnamed: 0', axis=1)\n",
    "all_per_norm = all_per_norm.drop('Rk', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "curr_per_adv_norm = pd.merge(norm_per, norm_adv[['PER', 'TS%', '3PAr',\n",
    "       'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%',\n",
    "       'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP','ID']],'left', on=['ID'])\n",
    "curr_per_adv_norm.to_csv('curr_per_adv_norm.csv')\n",
    "\n",
    "\n",
    "\n",
    "curr_per_adv_team_norm = pd.merge(curr_per_adv_norm, norm_team[['SOS', 'SRS', 'Team ORtg',\n",
    "       'Team DRtg', 'Team NRtg', 'Team Pace', 'Team FTr', 'Team 3PAr',\n",
    "       'Team TS%','Team ID']],'left', on=['Team ID'])\n",
    "curr_per_adv_team_norm.to_csv('curr_per_adv_team_norm.csv')\n",
    "\n",
    "all_data = pd.read_csv('all_per_adv_team_norm_mvps_dpoy.csv')\n",
    "\n",
    "#ROOKIES\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame called 'df' with a column 'Person' and a new column 'UHOH'\n",
    "# Also, assuming that you have a 'Year' column indicating the year\n",
    "\n",
    "# Sort the DataFrame by 'Person' and 'Year'\n",
    "all_data.sort_values(by=['Player', 'Season'], inplace=True)\n",
    "\n",
    "# Initialize a new column 'UHOH' with 0 for all rows\n",
    "all_data['Rookie'] = 0\n",
    "\n",
    "# Iterate through the DataFrame to check if a person appears in the previous year\n",
    "for index, row in all_data.iterrows():\n",
    "    person = row['Player']\n",
    "    \n",
    "    # Find the previous year's data for the same person\n",
    "    previous_years_row = all_data[(all_data['Player'] == person) & (all_data['Season'] < row['Season'])]\n",
    "    \n",
    "    # If the person did not appear in the previous year, set 'UHOH' to 1\n",
    "    if previous_years_row.empty:\n",
    "        all_data.at[index, 'Rookie'] = 1\n",
    "        \n",
    "        \n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame called 'df' with columns 'Person', 'PreviousYearFigure', and 'UHOH'\n",
    "# Also, assuming that the figure to check against is stored in a variable called 'certain_figure'\n",
    "\n",
    "certain_figure = 1  # Replace this with the figure you're checking against\n",
    "\n",
    "# Sort the DataFrame by 'Person' and 'Year' (assuming you have a 'Year' column)\n",
    "all_data.sort_values(by=['Player', 'Season'], inplace=True)\n",
    "\n",
    "# Initialize a new column 'UHOH' with 'No' for all rows\n",
    "all_data['All D Team'] = 0\n",
    "\n",
    "# Iterate through the DataFrame to check if the person met the certain figure in any previous year\n",
    "for index, row in all_data.iterrows():\n",
    "    person = row['Player']\n",
    "    \n",
    "    # Check if the person met the certain figure in any previous year\n",
    "    previous_years_met_condition = (all_data['Player'] == person) & (all_data['Season'] == row['Season']) & (all_data['MVP Winner'] >= certain_figure)\n",
    "    \n",
    "    # If met in any previous year, set 'UHOH' to 'Yes' for subsequent years\n",
    "    if previous_years_met_condition.any():\n",
    "        person_indices = (all_data['Player'] == person) & (all_data['Season'] >= row['Season'])\n",
    "        all_data.loc[person_indices, 'All D Team'] = 1\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "# Initialize a new column 'UHOH' with 'No' for all rows\n",
    "all_data['Won DPOY Before'] = 0\n",
    "\n",
    "# Iterate through the DataFrame to check if the person met the certain figure in any previous year\n",
    "for index, row in all_data.iterrows():\n",
    "    person = row['Player']\n",
    "    \n",
    "    # Check if the person met the certain figure in any previous year\n",
    "    previous_years_met_condition = (all_data['Player'] == person) & (all_data['Season'] == row['Season']) & (all_data['DPOY Winner'] >= certain_figure)\n",
    "    \n",
    "    # If met in any previous year, set 'UHOH' to 'Yes' for subsequent years\n",
    "    if previous_years_met_condition.any():\n",
    "        person_indices = (all_data['Player'] == person) & (all_data['Season'] >= row['Season'])\n",
    "        all_data.loc[person_indices, 'Won DPOY Before'] = 1\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "# Initialize a new column 'UHOH' with 'No' for all rows\n",
    "all_data['All D Team'] = 0\n",
    "\n",
    "# Iterate through the DataFrame to check if the person met the certain figure in any previous year\n",
    "for index, row in all_data.iterrows():\n",
    "    person = row['Player']\n",
    "    \n",
    "    # Check if the person met the certain figure in any previous year\n",
    "    previous_years_met_condition = (all_data['Player'] == person) & (all_data['Season'] == row['Season']) & (all_data['# Tm'] >= certain_figure)\n",
    "    \n",
    "    # If met in any previous year, set 'UHOH' to 'Yes' for subsequent years\n",
    "    if previous_years_met_condition.any():\n",
    "        person_indices = (all_data['Player'] == person) & (all_data['Season'] >= row['Season'])\n",
    "        all_data.loc[person_indices, 'All D Team'] = 1\n",
    "        \n",
    "                \n",
    "all_datahmm = all_data[all_data['Season'] == 2024]\n",
    "current_data = pd.merge(curr_per_adv_team_norm, all_datahmm[['MVP Winner', 'DPOY Winner',\n",
    "       '# Tm', 'ROTY Winner','Player', 'Won DPOY Before',\"All D Team\", \"Rookie\"]],'left', on=['Player'])\n",
    "current_data = current_data.drop_duplicates()\n",
    "current_data.to_csv('current_data.csv')\n",
    "\n",
    "mvp_cols = ['FG', 'FGA', 'FG%', '3P',\n",
    "       '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB',\n",
    "       'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS','AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'WS', 'BPM', 'VORP', 'SOS', 'SRS', 'Team ORtg', 'Team DRtg',\n",
    "       'Team NRtg',  'Team TS%', 'GameScore']\n",
    "dpoy_cols = ['ORB',\n",
    "       'DRB', 'TRB', 'STL', 'BLK', 'PF', 'PTS','STL%', 'BLK%', 'DWS', 'BPM', 'VORP', 'SOS', 'SRS', 'Team DRtg',\n",
    "       'Team NRtg', \"All D Team\"]\n",
    "roty_cols = [\"MP\",'FG', 'FGA', 'FG%', '3P',\n",
    "       '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB',\n",
    "       'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS','GameScore', 'USG%', 'WS', 'BPM',\"ROTY Winner\"]\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from joblib import dump,load\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy as sp\n",
    "\n",
    "loaded_model = load('prac_mvp_model.joblib')\n",
    "\n",
    "current = current_data[mvp_cols]\n",
    "current = current.drop_duplicates()\n",
    "current = current.fillna(current.mean())\n",
    "current[\"MVP Prediction\"] = loaded_model.predict(current)\n",
    "current.sort_values('MVP Prediction', ascending=False)\n",
    "current.sort_index(inplace=True)\n",
    "\n",
    "player_info = current_data[['ID', 'Player', 'Pos', 'Team', 'Team ID', 'Tm']]\n",
    "player_info.sort_index(inplace=True)\n",
    "\n",
    "current[['ID', 'Player', 'Pos', 'Team', 'Team ID', 'Tm']] = player_info[['ID', 'Player', 'Pos', 'Team', 'Team ID', 'Tm']]  \n",
    "\n",
    "current['MVP Probability'] = current['MVP Prediction'] / current['MVP Prediction'].sum() * 100\n",
    "\n",
    "loaded_model = load('prac_dpoy_model.joblib')\n",
    "\n",
    "dpoy = current_data[dpoy_cols] \n",
    "dpoy = dpoy.drop_duplicates()\n",
    "dpoy = dpoy.fillna(dpoy.mean())\n",
    "dpoy[\"DPOY Prediction\"] = loaded_model.predict(dpoy)\n",
    "dpoy.sort_values('DPOY Prediction', ascending=False)\n",
    "dpoy.sort_index(inplace=True)\n",
    "\n",
    "player_info = current_data[['ID', 'Player', 'Pos', 'Team', 'Team ID', 'Tm']]\n",
    "player_info.sort_index(inplace=True)\n",
    "\n",
    "dpoy[['ID', 'Player', 'Pos', 'Team', 'Team ID', 'Tm']] = player_info[['ID', 'Player', 'Pos', 'Team', 'Team ID', 'Tm']]  \n",
    "dpoy = dpoy.drop_duplicates()\n",
    "\n",
    "dpoy['DPOY Probability'] = dpoy['DPOY Prediction'] / dpoy['DPOY Prediction'].sum() * 100\n",
    "\n",
    "\n",
    "\n",
    "loaded_model = load('prac_roty_model.joblib')\n",
    "new_rookies = current_data[current_data['Rookie']==1]\n",
    "\n",
    "\n",
    "rooks = new_rookies[[\"MP\",'FG', 'FGA', 'FG%', '3P',\n",
    "       '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB',\n",
    "       'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'GameScore' ,'USG%', 'WS', 'BPM']] \n",
    "rooks = (rooks - rooks.mean()) / rooks.std()\n",
    "\n",
    "rooks = rooks.drop_duplicates()\n",
    "rooks[\"ROTY Prediction\"] = loaded_model.predict(rooks)\n",
    "rooks.sort_values('ROTY Prediction', ascending=False)\n",
    "rooks.sort_index(inplace=True)\n",
    "\n",
    "player_info = new_rookies[['ID', 'Player', 'Pos', 'Team', 'Team ID', 'Tm']]\n",
    "player_info.sort_index(inplace=True)\n",
    "\n",
    "rooks[['ID', 'Player', 'Pos', 'Team', 'Team ID', 'Tm']] = player_info[['ID', 'Player', 'Pos', 'Team', 'Team ID', 'Tm']]  \n",
    "\n",
    "rooks['ROTY Probability'] = rooks['ROTY Prediction'] / rooks['ROTY Prediction'].sum() * 100\n",
    "\n",
    "show_data = pd.merge(current_data, current[['MVP Prediction', 'ID']],'left', on=['ID'])\n",
    "show_data = show_data.drop_duplicates()\n",
    "\n",
    "show_data = pd.merge(show_data, dpoy[['DPOY Prediction', 'ID']],'left', on=['ID'])\n",
    "show_data = pd.merge(show_data, rooks[['ROTY Prediction', 'ID']],'left', on=['ID'])\n",
    "show_data = pd.merge(show_data, per,'left', on=['ID'])\n",
    "show_data['Team ID'] = show_data['Team ID_y']\n",
    "show_data = pd.merge(show_data, team,'left', on=['Team ID'])\n",
    "show_data = show_data.drop_duplicates()\n",
    "\n",
    "show_data.to_csv('show_data.csv')\n",
    "\n",
    "\n",
    "mvp_leaders = show_data.sort_values('MVP Prediction', ascending=False).head(20)[[\"MVP Prediction\",'Player_y', 'Pos_y', 'Team ID','W','L','Team NRtg_y', 'Age_y', \"PTS_y\", \"TRB_y\", \"AST_y\", \"STL_y\", \"BLK_y\", \"TOV_y\"]]\n",
    "mvp_leaders.rename(columns = {\"Player_y\": \"Player\", \"Pos_y\": \"Pos\", \"Age_y\": \"Age\", \"PTS_y\": \"PTS\", \"TRB_y\": \"TRB\", \"AST_y\": \"AST\",\"STL_y\": \"STL\",\"BLK_y\": \"BLK\",\"TOV_y\": \"TOV\",\"Team NRtg_y\": \"Team NRtg\" }, inplace=True)\n",
    "mvp_leaders['MVP Prediction'] = mvp_leaders['MVP Prediction'] * 100\n",
    "mvp_leaders['MVP Prediction'] = mvp_leaders['MVP Prediction'].round(2)  # Optional: Round the values to a specific number of decimal places\n",
    "mvp_leaders['MVP Prediction'] = mvp_leaders['MVP Prediction'].astype(str) + '%'  # Append '%' symbol to the values\n",
    "\n",
    "mvp_leaders.to_csv('C:\\\\Users\\\\Owner\\\\Downloads\\\\mvp_leaders.csv')\n",
    "\n",
    "dpoy_leaders = show_data.sort_values('DPOY Prediction', ascending=False).head(20)[[\"DPOY Prediction\",'Player_y', 'Pos_y', 'Team ID','W','L','Team DRtg_y', 'Age_y', \"PTS_y\", \"TRB_y\", \"AST_y\", \"STL_y\", \"BLK_y\", \"TOV_y\"]]\n",
    "dpoy_leaders.rename(columns = {\"Player_y\": \"Player\", \"Pos_y\": \"Pos\", \"Age_y\": \"Age\", \"PTS_y\": \"PTS\", \"TRB_y\": \"TRB\", \"AST_y\": \"AST\",\"STL_y\": \"STL\",\"BLK_y\": \"BLK\",\"TOV_y\": \"TOV\",\"Team DRtg_y\": \"Team DRtg\" }, inplace=True)\n",
    "dpoy_leaders['DPOY Prediction'] = dpoy_leaders['DPOY Prediction'] * 100\n",
    "dpoy_leaders['DPOY Prediction'] = dpoy_leaders['DPOY Prediction'].round(2)  # Optional: Round the values to a specific number of decimal places\n",
    "dpoy_leaders['DPOY Prediction'] = dpoy_leaders['DPOY Prediction'].astype(str) + '%'  # Append '%' symbol to the values\n",
    "\n",
    "dpoy_leaders.to_csv('C:\\\\Users\\\\Owner\\\\Downloads\\\\dpoy_leaders.csv')\n",
    "\n",
    "\n",
    "\n",
    "roty_leaders = show_data.sort_values('ROTY Prediction', ascending=False).head(20)[[\"ROTY Prediction\",'Player_y', 'Pos_y', 'Team ID','W','L','Team NRtg_y', 'Age_y', \"PTS_y\", \"TRB_y\", \"AST_y\", \"STL_y\", \"BLK_y\", \"TOV_y\"]]\n",
    "roty_leaders.rename(columns = {\"Player_y\": \"Player\", \"Pos_y\": \"Pos\", \"Age_y\": \"Age\", \"PTS_y\": \"PTS\", \"TRB_y\": \"TRB\", \"AST_y\": \"AST\",\"STL_y\": \"STL\",\"BLK_y\": \"BLK\",\"TOV_y\": \"TOV\",\"Team NRtg_y\": \"Team NRtg\" }, inplace=True)\n",
    "roty_leaders['ROTY Prediction'] = roty_leaders['ROTY Prediction'] * 100\n",
    "roty_leaders['ROTY Prediction'] = roty_leaders['ROTY Prediction'].round(2)  # Optional: Round the values to a specific number of decimal places\n",
    "roty_leaders['ROTY Prediction'] = roty_leaders['ROTY Prediction'].astype(str) + '%'  # Append '%' symbol to the values\n",
    "\n",
    "roty_leaders.to_csv('C:\\\\Users\\\\Owner\\\\Downloads\\\\roty_leaders.csv')\n",
    "\n",
    "# Define the number of columns to highlight\n",
    "num_rows_to_highlight = 5\n",
    "\n",
    "#Graphs\n",
    "import plotly.graph_objects as go\n",
    "# Convert DataFrame to Plotly table\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(mvp_leaders.columns),\n",
    "                fill_color='blue',\n",
    "                align='left'\n",
    "               , font=dict(color='white')  # Set the text color for the header\n",
    "               ),\n",
    "    cells=dict(values=[mvp_leaders[col] for col in mvp_leaders.columns],\n",
    "            fill_color=[['skyblue' if i < num_rows_to_highlight else 'white' for i in range(len(mvp_leaders))] for col in mvp_leaders.columns],\n",
    "               align='left', height=50))\n",
    "])\n",
    "\n",
    "# Update layout for better appearance and larger cells\n",
    "fig.update_layout(\n",
    "    height=1000,  # Set the height to your desired value\n",
    "    showlegend=False,\n",
    "    font=dict(size=14),  # Adjust font size\n",
    "    margin=dict(l=20, r=20, b=20, t=20),\n",
    "    width=[None, 1800] # Adjust margin\n",
    ")\n",
    "\n",
    "\n",
    "# Show the figure\n",
    "mvp_leaders_graph = fig.write_html(\"C:\\\\Users\\\\Owner\\\\Downloads\\\\Portfolio Website\\\\MVP_df.html\")\n",
    "# mvp_leaders = mvp_leaders.to_html(\"C:\\\\Users\\\\Owner\\\\Downloads\\\\Portfolio Website\\\\MVP_df.html\", classes='table table-bordered table-striped', index=False)\n",
    "\n",
    "#Graphs\n",
    "import plotly.graph_objects as go\n",
    "# Convert DataFrame to Plotly table\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(dpoy_leaders.columns),\n",
    "                fill_color='red',\n",
    "                align='left'),\n",
    "    cells=dict(values=[dpoy_leaders[col] for col in dpoy_leaders.columns],\n",
    "            fill_color=[['mistyrose' if i < num_rows_to_highlight else 'white' for i in range(len(dpoy_leaders))] for col in dpoy_leaders.columns],\n",
    "               align='left', height=50))\n",
    "])\n",
    "\n",
    "# Update layout for better appearance and larger cells\n",
    "fig.update_layout(\n",
    "    height=1000,  # Set the height to your desired value\n",
    "    showlegend=False,\n",
    "    font=dict(size=14),  # Adjust font size\n",
    "    margin=dict(l=20, r=20, b=20, t=20),\n",
    "    width=[None, 1800] # Adjust margin\n",
    ")\n",
    "\n",
    "dpoy_leaders = fig.write_html(\"C:\\\\Users\\\\Owner\\\\Downloads\\\\Portfolio Website\\\\DPOY_df.html\")\n",
    "\n",
    "\n",
    "# dpoy_leaders = dpoy_leaders.to_html(\"C:\\\\Users\\\\Owner\\\\Downloads\\\\Portfolio Website\\\\DPOY_df.html\", classes='table table-bordered table-striped', index=False)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "# Convert DataFrame to Plotly table\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(roty_leaders.columns),\n",
    "                fill_color='darkseagreen',\n",
    "                align='left'),\n",
    "    cells=dict(values=[roty_leaders[col] for col in roty_leaders.columns],\n",
    "            fill_color=[['mediumspringgreen' if i < num_rows_to_highlight else 'white' for i in range(len(roty_leaders))] for col in roty_leaders.columns],\n",
    "               align='left', height=50))\n",
    "])\n",
    "\n",
    "\n",
    "# Update layout for better appearance and larger cells\n",
    "fig.update_layout(\n",
    "    height=1000,  # Set the height to your desired value\n",
    "    showlegend=False,\n",
    "    font=dict(size=14),  # Adjust font size\n",
    "    margin=dict(l=20, r=20, b=20, t=20), # Adjust margin\n",
    "    width=[None, 1800]\n",
    "\n",
    ")\n",
    "\n",
    "roty_leaders = fig.write_html(\"C:\\\\Users\\\\Owner\\\\Downloads\\\\Portfolio Website\\\\ROTY_df.html\")\n",
    "\n",
    "\n",
    "# roty_leaders = roty_leaders.to_html(\"C:\\\\Users\\\\Owner\\\\Downloads\\\\Portfolio Website\\\\ROTY_df.html\", classes='table table-bordered table-striped', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "256977a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpoy_leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25c9110c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mvp_leaders_graph\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "mvp_leaders_graph.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d8d70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
